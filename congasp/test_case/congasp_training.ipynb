{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONGASp Training on Custom Bin Count Data\n",
    "This notebook demonstrates how to load your bin count and ploidy data, prepare it for CONGASp, train the model, and inspect/save the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/app')\n",
    "import pandas as pd\n",
    "import torch\n",
    "from congas.Interface import Interface\n",
    "from congas.models.LatentCategorical import LatentCategorical\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceGraph_ELBO\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Bin Count and Ploidy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data folder (adjust if running inside Docker)\n",
    "data_dir = './'  # Current directory\n",
    "\n",
    "# Load bin count matrix (bins x cells)\n",
    "bin_counts = pd.read_csv(data_dir + 'bin_counts_for_python.csv', index_col=0)\n",
    "\n",
    "# Load ploidy file\n",
    "ploidy_df = pd.read_csv(data_dir + 'bin_ploidy.csv')\n",
    "pld = torch.tensor(ploidy_df['ploidy'].values, dtype=torch.float32)\n",
    "\n",
    "# Split columns based on \"146p\" in column names\n",
    "atac_cols = [col for col in bin_counts.columns if \"146p\" in col]\n",
    "rna_cols = [col for col in bin_counts.columns if \"146p\" not in col]\n",
    "\n",
    "# Subset DataFrames\n",
    "bin_counts_atac = bin_counts[atac_cols]\n",
    "bin_counts_rna = bin_counts[rna_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for CONGASp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors\n",
    "data_rna = torch.tensor(bin_counts_rna.values, dtype=torch.float32)\n",
    "data_atac = torch.tensor(bin_counts_atac.values, dtype=torch.float32)\n",
    "\n",
    "# Normalization factors\n",
    "norm_factor_rna = data_rna.sum(dim=0)\n",
    "norm_factor_atac = data_atac.sum(dim=0)\n",
    "\n",
    "# Number of segments (bins)\n",
    "segments = data_rna.shape[0]  # Should be the same for both\n",
    "\n",
    "# Prepare data_dict for CONGASp\n",
    "data_dict = {\n",
    "    'data_rna': data_rna,\n",
    "    'norm_factor_rna': norm_factor_rna,\n",
    "    'data_atac': data_atac,\n",
    "    'norm_factor_atac': norm_factor_atac,\n",
    "    'pld': pld,\n",
    "    'segments': segments\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO: 0.176901128  : 100%|██████████| 200/200 [11:04<00:00,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose model, optimizer, and loss\n",
    "model = LatentCategorical\n",
    "optimizer = ClippedAdam\n",
    "loss = TraceGraph_ELBO\n",
    "\n",
    "# Initialize interface\n",
    "interface = Interface(model, optimizer, loss)\n",
    "interface.initialize_model(data_dict)\n",
    "\n",
    "# Set required model parameters\n",
    "param_dict = {\n",
    "    'K': 3,  # Number of clusters\n",
    "    'theta_shape_rna': torch.ones(segments) * 20.0,  # Shape parameter for RNA\n",
    "    'theta_rate_rna': torch.ones(segments) * 0.5,    # Rate parameter for RNA\n",
    "    'theta_shape_atac': torch.ones(segments) * 10.0, # Shape parameter for ATAC\n",
    "    'theta_rate_atac': torch.ones(segments) * 0.5,   # Rate parameter for ATAC\n",
    "    'lambda': 0.5,  # Weight between RNA and ATAC (0.5 = equal weight)\n",
    "    'multiome': False,  # Set to True since you have both RNA and ATAC\n",
    "    'equal_mixture_weights': True,  # Use same mixture weights for both modalities\n",
    "    'likelihood_rna': 'NB',  # Negative Binomial for RNA\n",
    "    'likelihood_atac': 'NB',  # Negative Binomial for ATAC\n",
    "    'nb_size_init_rna': torch.ones(segments) * 10.0,  # NB size parameter for RNA\n",
    "    'nb_size_init_atac': torch.ones(segments) * 5.0,  # NB size parameter for ATAC\n",
    "    'hidden_dim': 5  # Number of possible copy number states\n",
    "}\n",
    "\n",
    "interface.set_model_params(param_dict)\n",
    "\n",
    "# Train the model\n",
    "losses, n_obs = interface.run(steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Up and Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inspect and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing assignment probabilities\n",
      "Cluster assignments: [0 0 0 ... 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "params = interface.learned_parameters()\n",
    "\n",
    "# Save results as numpy file\n",
    "np.save(data_dir + 'congas_results.npy', params)\n",
    "\n",
    "# Optionally, display cluster assignments\n",
    "if 'assignment_rna' in params:\n",
    "    print('Cluster assignments:', params['assignment_rna'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
